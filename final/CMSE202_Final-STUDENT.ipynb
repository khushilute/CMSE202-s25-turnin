{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exam (Individual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Khushi Lute</p>\n",
    "### <p style=\"text-align: right;\"> &#9989; khushilute</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Final (Section 004 - Spring 25)\n",
    "\n",
    "\n",
    "# &#128721; READ EVERYTHING CAREFULLY\n",
    "\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed thus far this semester. In particular, you'll practice setting up a GitHub repository, committing and pushing repository changes, downloading data with command line tools, performing some data analysis, possibly using a new Python package, and writing a python class. You should find that you have all of the skills necessary to complete this exam with even just eight weeks of CMSE 202 under your belt!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. Once you've read through it, try doing Parts 1 and 2 first so that you have your repository set up and you download all necessary data files as they will be necessary to complete the assigned tasks. Let your instructor know right away if you have problems downloading the data!\n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. **However**: The use of any person-to-person communication software is absolutely not acceptable. If you are seen accessing your email, using a chat program (e.g. Slack), or any sort of collaborative cloud storage or document software (e.g. Google Documents), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**Important Guidelines on AI Tool Usage**\n",
    "\n",
    "This exam allows the use of AI tools (such as ChatGPT, Claude, HiTA) with specific guidelines that mirror real-world professional practices. These tools should enhance your learning and problem-solving process, not replace your intellectual engagement. Here are the key requirements:\n",
    "\n",
    "1. **Appropriate Use of AI**:\n",
    "   - Use AI as a learning assistant to understand concepts, debug code, or get unstuck\n",
    "   - Use AI to improve your solution approach or verify your thinking\n",
    "   - Use AI to learn about new Python packages or functions you might need\n",
    "\n",
    "2. **Prohibited Uses**:\n",
    "   - Direct copying of AI-generated solutions without understanding\n",
    "   - Asking AI to complete entire questions without your intellectual input\n",
    "   - Using AI to modify provided starter code or test cases\n",
    "   - Using AI to circumvent learning objectives or problem requirements\n",
    "\n",
    "3. **Documentation Requirements**:\n",
    "   - You must cite any AI assistance received by adding a comment that includes:\n",
    "     * The AI tool used\n",
    "     * The specific question you asked\n",
    "     * How you modified or improved upon the AI's suggestion\n",
    "   - Example: \"# AI assistance: Used Claude to understand lmfit parameter initialization. Modified the suggested approach to include custom bounds.\"\n",
    "\n",
    "4. **Evaluation Implications**:\n",
    "   - Questions showing signs of direct AI solution copying will receive zero points\n",
    "   - Evidence of not following problem instructions, even if AI-suggested, will result in zero points\n",
    "   - Modified starter code or test cases will result in zero points for that question\n",
    "\n",
    "Remember: The goal is to demonstrate your understanding and problem-solving abilities. AI tools should support your learning, not replace your critical thinking and coding skills.\n",
    "\n",
    "**Note**: Traditional open internet resources (documentation, Stack Overflow, etc.) remain available, but person-to-person communication tools are not permitted.\"\n",
    "\n",
    "**Keep your eyes on your screen!** Unfortunately, there isn't enough space in the room for everyone to sit at their own table so please do your best to keep your eyes on your own screen. This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Moira](https://media.giphy.com/media/26gs78HRO8sOuhTkQ/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "Navigate through the midterm using these links:\n",
    "\n",
    "\n",
    "* [Part 0: Upgrade packages](#part0) (1 point)\n",
    "* [Part 1: Git](#part1) (9 points)\n",
    "* [Part 2: Data Preprocessing](#part2) (27 points)\n",
    "* [Part 3: Logistic Regression](#part3) (19 points)\n",
    "* [Part 4: Support Vector Machines](#part4) (14 points)\n",
    "* [Part 5: Comparison and Conclusion](#part5) (8 points)\n",
    "* [Part 6: Conceptual Questions](#part6) (10 points)\n",
    "* [Part 7: Conclusion](#conclusion) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:50:14.352819Z",
     "start_time": "2022-12-07T03:50:14.350105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total grade for this final is 93\n"
     ]
    }
   ],
   "source": [
    "grades = [1, 9, 27, 19, 14, 8, 10, 5]\n",
    "\n",
    "print(f\"The total grade for this final is {sum(grades)}\" )\n",
    "# Should print 93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"part0\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 0: Upgrade Packages\n",
    "\n",
    "**&#9989; Question 0.1 (1 point)**: Run the cell below. Do you have the correct packages ? If not upgrade them. **You must do this in order to avoid issues in the rest of the notebook.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:15:16.292936Z",
     "start_time": "2022-12-07T03:15:16.283043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn version should be 1.6.0 and I have 1.6.0\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm \n",
    "\n",
    "from sklearn import __version__ as sk_version\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "print(f\"Sklearn version should be 1.6.0 and I have {sk_version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id=\"part1\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## Part 1: Git (9 points)\n",
    "\n",
    "For this assignment, you're going to add it to the `cmse202-s25-turnin` repository you created in class so that you can track your progress on the assignment and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Question 1.1 (1 point)**: Navigate to your `cmse202-s25-turnin` **local** repository and create a new directory called `final` and copy this notebook in that new directory.\n",
    "\n",
    "``` bash\n",
    "the \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.2 (3 points)** Check the status of your local `git`.\n",
    "\n",
    "``` bash \n",
    "# Put the command you used to check the status of git\n",
    "\n",
    "```\n",
    "Copy and paste below the output of the command.\n",
    "\n",
    "``` bash\n",
    "# Paste it here\n",
    "```\n",
    "\n",
    "What is the name of the branch you are in ? \n",
    "\n",
    "``` bash\n",
    "# Put your answer here\n",
    "```\n",
    "\n",
    "**Important:** You should be in the `main` branch. If you are not switch to the `main` branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.3 (3 points):**\n",
    "Add your name and GitHub username to the top of the notebook, then add and commit **ONLY** the notebook.\n",
    "\n",
    "``` bash\n",
    "# Put the command(s) to add and commit here \n",
    "```\n",
    "\n",
    "What is the commit message you used ?\n",
    "\n",
    "``` bash\n",
    "# Answer the question here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.4 (1 point):** Before moving on. Check that the notebook you are working on is the correct one. Run the following cell. **Are you in the new folder you just created?** If not close this notebook and open the one in the `final` folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T20:23:32.165597Z",
     "start_time": "2022-12-05T20:23:31.986031Z"
    }
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.5 (1 point):** Finally push the updated notebook to GitHub.\n",
    "\n",
    "``` bash\n",
    "# Put the command you used to push to GitHub here.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" repository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the notebook, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-s25-turnin`\" repository inside the `final` directory that you just created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "---\n",
    "<a id=\"part2\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Auto MPG Dataset Analysis Assignment\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this assignment, you will analyze the Auto MPG dataset, which contains information about various car models. You'll create a binary classification task, comparing logistic regression and Support Vector Machine (SVM) models to predict whether a car has above-median fuel efficiency.\n",
    "\n",
    "The Auto MPG dataset contains data about automobile models from the late 1970s and early 1980s, including characteristics such as horsepower, weight, acceleration, and their fuel efficiency measured in miles per gallon (MPG).\n",
    "\n",
    "For this assignment, you will:\n",
    "1. Load and explore the dataset\n",
    "2. Create a binary target variable based on MPG values\n",
    "3. Build classification models using logistic regression and SVM\n",
    "4. Compare model performance using appropriate metrics\n",
    "\n",
    "\n",
    "## Part 2: Data Loading and Exploratory Data Analysis (27 points)\n",
    "\n",
    "**&#9989; (6 points) Task 2.1:** You can get the dataset at this link `https://archive.ics.uci.edu/dataset/9/auto+mpg`\n",
    "\n",
    "* Load the Auto MPG dataset using pandas. (3 points)\n",
    "* Make sure the put names on the columns of the dataframe (2 points)\n",
    "* Display the first 10 rows (1 point)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T20:23:36.383889Z",
     "start_time": "2022-12-05T20:23:36.381940Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "**&#9989; (6 points) Task 2.2:** Perform basic data cleaning. Write code in the next cell to answer the following questions\n",
    "\n",
    "* Are there any missing values or null values? If so what columns and how many? (3 points)\n",
    "* Drop the rows with the missing values. (1 point)\n",
    "* Drop the `car_name` column. (1 point)\n",
    "* Check your work by showing that there are no missing values (1 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (1 point) Task 2.3:** Let's do some EDA. Run the code below and analyze the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical features\n",
    "\n",
    "# Convert 'origin' to categorical\n",
    "data_cleaned['origin'] = data_cleaned['origin'].astype('category')\n",
    "\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(data_cleaned.describe())\n",
    "\n",
    "# Set up the visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Distribution of MPG\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data_cleaned['mpg'], kde=True, bins=20)\n",
    "plt.title('Distribution of Miles Per Gallon (MPG)')\n",
    "plt.xlabel('MPG')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('mpg_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = data_cleaned.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "plt.show()\n",
    "\n",
    "# # Scatter plots of key relationships\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# # MPG vs. Weight\n",
    "# sns.scatterplot(data=data_cleaned, x='weight', y='mpg', ax=axes[0, 0])\n",
    "# axes[0, 0].set_title('MPG vs. Weight')\n",
    "# axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# # MPG vs. Horsepower\n",
    "# sns.scatterplot(data=data_cleaned, x='horsepower', y='mpg', ax=axes[0, 1])\n",
    "# axes[0, 1].set_title('MPG vs. Horsepower')\n",
    "# axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# # MPG vs. Displacement\n",
    "# sns.scatterplot(data=data_cleaned, x='displacement', y='mpg', ax=axes[1, 0])\n",
    "# axes[1, 0].set_title('MPG vs. Displacement')\n",
    "# axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# # MPG vs. Model Year\n",
    "# sns.boxplot(data=data_cleaned, x='model_year', y='mpg', ax=axes[1, 1])\n",
    "# axes[1, 1].set_title('MPG by Model Year')\n",
    "# axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('mpg_relationships.png')\n",
    "# plt.show()\n",
    "\n",
    "# # MPG by origin\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.boxplot(data=data_cleaned, x='origin', y='mpg')\n",
    "# plt.title('MPG by Origin')\n",
    "# plt.xlabel('Origin (1: USA, 2: Europe, 3: Japan)')\n",
    "# plt.ylabel('MPG')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.savefig('mpg_by_origin.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (4 points) Task 2.3:** Answer these questions\n",
    "\n",
    "* Explain the first histogram. What is being plot here? What is frequency? (2 points)\n",
    "* Looking at the correlation matrix plot. What are the features that most strongly correlate with `mpg`? (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (4 points) Task 2.4:** Create a new binary target variable:\n",
    "\n",
    "* Calculate and print the median MPG value (1 point)\n",
    "* Create a new column called 'high_mpg' that equals 1 if a car's MPG is above the median, and 0 otherwise (2 points)\n",
    "* Verify the class distribution of your new target variable. In other words how many cars are above and how many are below the median. Is it 50:50? (1 point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989;(2 points) Task 2.5:** Split the data into training (70%) and testing (30%) sets using an appropriate random seed value. Make sure you have the same class distribution of high mpg in the train/test dataset as in the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989;(2 points) Task 2.6:** Run the following code and answer this question:\n",
    "\n",
    "* Do you think the data is linearly separable? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_cleaned.drop('mpg', axis = 1), hue='high_mpg', diag_kind='kde', palette='Set1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 2\", and push the changes to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "---\n",
    "<a id=\"part3\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## Part 3: Logistic Regression Analysis (19 points)\n",
    "\n",
    "**&#9989; Task 3.1:** Preprocess your data appropriately for logistic regression:\n",
    "\n",
    "An important part of the preparing the data for the ML part is scaling and encoding. We have not covered this in class, so I am not asking you to do it. The code below takes care of this run it and make sure you don't get any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code without modifying it, apart from the name of the dataset\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Preprocess data for logistic regression\n",
    "# Handle categorical variables (one-hot encoding for 'origin')\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "origin_encoded = encoder.fit_transform(X_train[['origin']])\n",
    "origin_cols = [f'origin_{i+2}' for i in range(origin_encoded.shape[1])]\n",
    "origin_train_df = pd.DataFrame(origin_encoded, columns=origin_cols, index=X_train.index)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year']\n",
    "X_train_num = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[numerical_cols]),\n",
    "    columns=numerical_cols,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Combine numerical and encoded categorical features\n",
    "X_train_processed = pd.concat([X_train_num, origin_train_df], axis=1)\n",
    "\n",
    "# Process test data\n",
    "origin_encoded_test = encoder.transform(X_test[['origin']])\n",
    "origin_test_df = pd.DataFrame(origin_encoded_test, columns=origin_cols, index=X_test.index)\n",
    "\n",
    "X_test_num = pd.DataFrame(\n",
    "    scaler.transform(X_test[numerical_cols]),\n",
    "    columns=numerical_cols,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "X_test_processed = pd.concat([X_test_num, origin_test_df], axis=1)\n",
    "\n",
    "print(\"\\nProcessed training data shape:\", X_train_processed.shape)\n",
    "print(\"Processed testing data shape:\", X_test_processed.shape)\n",
    "print(\"\\nFirst 5 rows of processed training data:\")\n",
    "display(X_train_processed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989;(7 points) Task 3.2:** Fit a logistic regression model using the `statsmodels` library:\n",
    "\n",
    "* Use the training data to fit the model (2 points)\n",
    "* Print the summary of your model results (1 point)\n",
    "* Interpret the coefficients and statistical significance of features (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Interpret the coefficients of the logistic regression model here. What are the most important features? Why? \n",
    "How does this compare to the correlation matrix from above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (6 points) Task 3.3:** Evaluate the logistic regression model:\n",
    "\n",
    "* Make predictions on the test set (1 point)\n",
    "* Create a confusion matrix (1 point)\n",
    "* Display the confusion matrix as a heatmap with Blues colormap (2 points)\n",
    "* Calculate and print accuracy, precision, recall (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (4 points) Task 3.4:** Given the results above do you think that the data is linearly separable? Explain and compare with your answer from Task 2.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 3\", and push the changes to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "<a id=\"part4\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## Part 4: Support Vector Machine Analysis (14 points)\n",
    "\n",
    "**&#9989; (4 points) Task 4.1:** Implement an SVM classifier with RBF kernel:\n",
    "- Initialize an SVM model with RBF kernel (1 point)\n",
    "- Define a grid of hyperparameters to search (C and gamma) (2 points)\n",
    "- Use the option `cv = 5` when fitting (This is 5-fold cross-validation to find the optimal parameters) (1 point)\n",
    "- Report the best parameters found and the cross-validation score (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:22:14.395392Z",
     "start_time": "2022-12-07T03:22:14.392835Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (8 points) Task 4.3:** Evaluate the optimized SVM model:\n",
    "- Train the model with the best parameters on the training data (2 points)\n",
    "- Make predictions on the test set (1 point)\n",
    "- Create a confusion matrix (1 point)\n",
    "- Display the confusion matrix using a heatmap with Blues colormap (2 points)\n",
    "- Calculate and print accuracy, precision, recall (2 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 4\", and push the changes to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id=\"part5\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## Part 5: Model Comparison and Conclusion (8 points)\n",
    "\n",
    "**&#9989; (4 points) Task 5.1:** Compare the performance of the logistic regression and SVM models:\n",
    "- Create a side-by-side comparison of confusion matrices (2 points)\n",
    "- Make an histogram comparing accuracy, precision, recall (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; (2 points) Task 5.2:** Explain which model you would recommend for this classification task and why:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 5\", and push the changes to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "---\n",
    "<a id=\"part6\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 6. Conceptual Questions (10 Points)\n",
    "\n",
    "The following questions probe your understanding of  `recall` and `precision`. You’ll be given a specific scenario, and you will need to decide whether to select a Machine Learning model that maximizes `recall` or `precision`.\n",
    "\n",
    "\n",
    "**&#9989; Question 6.1 (4 points):**  A new disease has been detected in Sweden. Doctors have taken multiple measurements of patients and passed them along to you. You’ve tested various models to predict which patients have the new disease. The Swedish health experts have told you it is critical that they identify **all** of the patients with the new disease so they can put them into quarantine. They tell you that it doesn’t matter if your model accidentally flags some people as having the disease even when they don’t, as it’s much better to tell people who aren’t sick to quarantine than to tell a sick person they don’t need to quarantine.\n",
    "\n",
    "Given this situation, should you choose the model that maximizes `recall` or the model that maximizes `precision`? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**&#9989; Question 6.2 (4 points):**\n",
    "You are working for the state of Michigan, helping them with their new unemployment insurance program. You’ve created various models that are meant to detect fraud–i.e., determine whether or not someone applied for unemployment insurance when they shouldn’t have. Your boss tells you that it’s critical that your model doesn’t accidentally accuse an innocent person of fraud. They say it’s fine if your model misses some people who committed fraud as long as there are no false accusations. \n",
    "\n",
    "Given this situation, should you choose the model that maximizes `recall` or the model that maximizes `precision`? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!** (2 points)\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 6\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id=\"conclusion\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 7. Conclusion (3 points)\n",
    "\n",
    "Make sure all of your changes to your repository are committed and pushed to GitHub. \n",
    "Before you leave\n",
    "\n",
    "1. Have you added your name and github username at the top of this notebook? ? (1 point)\n",
    "\n",
    "2. Push the changes to your GitHub repository (1 point)\n",
    "\n",
    "3. Upload your notebook to D2L in case something went wrong with your repository or if you couldn't get the repository to work.  (1 point)\n",
    "   \n",
    "4. Before submitting the notebook make sure to Restart your kernel and Run all cells. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Final\n",
    "\n",
    "![Moira2](https://media.giphy.com/media/d1E2HnwywoTkES08/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#169; Copyright 2022,  Department of Computational Mathematics, Science and Engineering at Michigan State University"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
