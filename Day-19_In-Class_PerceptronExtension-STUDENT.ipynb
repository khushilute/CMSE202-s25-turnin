{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48015ee0-9b0e-4d33-ab06-842d8791012a",
   "metadata": {},
   "source": [
    "# In-Class Challenge Assignment: Experimenting with the Perceptron\n",
    "# Day 19 Extension\n",
    "# CMSE 202"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87657ab-983d-4a2e-983d-4c3ef9847d08",
   "metadata": {},
   "source": [
    "## Now that you have a working Perceptron Classifier... let's experiment with it a bit!\n",
    "\n",
    "When building and testing your Perceptron Classifier you used a simplified version of the iris dataset that has been reduced to just two features and two class labels. \n",
    "\n",
    "### Will your Perceptron classifier work on a more complex dataset?\n",
    "\n",
    "Another widely used dataset for experimenting with binary classification is the [sonar dataset](https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)).\n",
    "\n",
    "A version of this dataset can be found here:\n",
    "\n",
    "`https://raw.githubusercontent.com/msu-cmse-courses/cmse202-supplemental-data/main/data/sonar.csv`\n",
    "\n",
    "Make sure you take a moment to read the [UC Irvine Machine Learning Repository page](https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)) to understand exactly what is in this dataset, but essentially is a collection of sonar measurements of rocks and \"mines\" (metal cynlinders). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e2e8b-c372-4871-9862-5df2a65e9afa",
   "metadata": {},
   "source": [
    "---\n",
    "### Testing your new tool and exploring others\n",
    "\n",
    "With any time that you have left in class, see if you can accomplish the following:\n",
    "\n",
    "1. Load up the sonar dataset and change the class labels so that they can be used with the Perceptron classifier.\n",
    "\n",
    "2. Use the Perceptron classifier you built from scratch to see how well you can do at distinguishing rocks from mines. You may need to make some modifications to your code if you didn't build it to be flexible enough to accept an arbitary number of data deatures. Experiment with the learning rate and number of iterations to see how high of an accuracy you can get with your classifier.\n",
    "\n",
    "3. If you get your Perceptron classifier working, can you figure out how to use the Perceptron Classifier that is available in [scikit-learn](https://scikit-learn.org/stable/index.html)? You may need to do a bit of Google searching and exploration of the documentation to figure this out. How well does the scikit-learn version do compared to the one you built?\n",
    "\n",
    "<!--\n",
    "4. If you're feeling really ambitious, can you build a Perceptron classifier with [Tensorflow](https://www.tensorflow.org/)? Remember, the Perceptron is basically just a single-neuron single-layer neural network. This requires installation of Tensorflow and relevant APIs.\n",
    "-->\n",
    "\n",
    "4. The logistic regression model (Day 15) is also a multi-variable classifier. Use it on the same dataset. Compare the results of your perceptron classifier against that obtained from and discuss your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d82c234-ce27-4854-bbfc-96629f3f3028",
   "metadata": {},
   "source": [
    "---\n",
    "&#9989; **Do This**: Load up the sonar data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d795f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Perceptron as SklearnPerceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Step 1: Load the dataset from the given URL\n",
    "url = \"https://raw.githubusercontent.com/msu-cmse-courses/cmse202-supplemental-data/main/data/sonar.csv\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "X = data.iloc[:, :-1].values  # Features (all columns except the last)\n",
    "y = data.iloc[:, -1].values   # Labels (last column)\n",
    "\n",
    "# Convert labels to binary: 'M' -> 1, 'R' -> 0\n",
    "y = np.where(y == 'M', 1, 0)\n",
    "\n",
    "# Ensure X is a NumPy array (this step guarantees correct data types for matrix operations)\n",
    "X = np.array(X)\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 4: Define your custom Perceptron classifier\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2a6ae6-4295-4455-baba-26a15b0ef359",
   "metadata": {},
   "source": [
    "Copy your percentron class to the cell below. **Note** sklearn has a **Perceptron** function. We should avoid using the same function name of your perceptron class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccdf7ae4-71bf-4357-8fad-50b29631c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyPerceptron:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def _activation(self, x):\n",
    "        \"\"\"Step activation function\"\"\"\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the perceptron model using the provided training data.\"\"\"\n",
    "        # Initialize weights and bias to zero\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        self.bias = 0\n",
    "\n",
    "        # Gradient Descent / Perceptron learning rule\n",
    "        for _ in range(self.n_iterations):\n",
    "            for i in range(len(y)):\n",
    "                linear_output = np.dot(X[i], self.weights) + self.bias\n",
    "                predicted = self._activation(linear_output)\n",
    "                \n",
    "                # Perceptron weight update rule\n",
    "                if predicted != y[i]:\n",
    "                    error = y[i] - predicted\n",
    "                    self.weights += self.learning_rate * error * X[i]\n",
    "                    self.bias += self.learning_rate * error\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using the trained perceptron model.\"\"\"\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return np.array([self._activation(x) for x in linear_output])\n",
    "\n",
    "# Usage example:\n",
    "# perceptron = MyPerceptron(learning_rate=0.01, n_iterations=1000)\n",
    "# perceptron.fit(X_train, y_train)\n",
    "# y_pred = perceptron.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23a7a6-c8fb-4f54-82bd-5c8afc031de4",
   "metadata": {},
   "source": [
    "Train your percentron class with sonar data. What's the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cad22774-8b2e-44ea-ac54-67a0a94bf570",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Step 4: Train the Perceptron model\u001b[39;00m\n\u001b[1;32m     22\u001b[0m perceptron \u001b[38;5;241m=\u001b[39m MyPerceptron(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, n_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mperceptron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Step 5: Make predictions on the test set\u001b[39;00m\n\u001b[1;32m     26\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m perceptron\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m, in \u001b[0;36mMyPerceptron.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iterations):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y)):\n\u001b[0;32m---> 23\u001b[0m         linear_output \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n\u001b[1;32m     24\u001b[0m         predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activation(linear_output)\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# Perceptron weight update rule\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Load the Sonar dataset\n",
    "url = \"https://raw.githubusercontent.com/msu-cmse-courses/cmse202-supplemental-data/main/data/sonar.csv\"\n",
    "df = pd.read_csv(url, header=None)\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "# Replace class labels ('R' and 'M') with 0 and 1\n",
    "df[60] = df[60].map({'R': 0, 'M': 1})\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(60, axis=1).values  # Features (all columns except the last one)\n",
    "y = df[60].values  # Labels (last column)\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train the Perceptron model\n",
    "perceptron = MyPerceptron(learning_rate=0.01, n_iterations=1000)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on Sonar dataset: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ceb7a-95db-49aa-81b6-ec094265ffdc",
   "metadata": {},
   "source": [
    "---\n",
    "&#9989; **Do This**: Use the **Perceptron** function from sklearn library to classify the same dataset in the cell below. Compare to your percentron classifier, how is the performance of the percetron in the sklearn library?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88194cf3-de9b-42d6-bdbb-d3f4ab4957bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702ab39-642d-413f-97ed-23f705e15611",
   "metadata": {},
   "source": [
    "---\n",
    "&#9989; **Do This**: Use **logistic regress model** from statsmodel library to classify the same dataset in the cell below. \n",
    "\n",
    "* Note that the full sonar data set contains some values that will result in singular values in the logistic regression. Thus, we will use only the first 40 attritbutes (columns) in the sonar dataset. The class label is still the last column in the sonar dataset.\n",
    "* We will add constant to the model, which is equivalent to the bias weight.\n",
    "* The Logit function requires the labels to be 1 or 0. You'll need to replace '-1' in the labels to '0' for the Logit function.\n",
    "* Let's set test_size = 0.15 in the train-test split, and fit the model using the training set.\n",
    "* Predict the labels of the test set. How is the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65817556-9766-40ae-bcbb-96e12a04c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fe8700-a3da-42e1-9c24-8e57bcf2c632",
   "metadata": {},
   "source": [
    "Train your percentron class with the training set. \n",
    "* Don't forget that the labels in the sonar dataset is '-1'. You probably need to convert '0' in the train_labels and test_labels back to '-1'.\n",
    "* Use the features in the test set in your percetron prediction function to predict the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817bb68-b9c9-4cfe-8ebf-0ae48b7c7fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e6b82f-88ad-4b05-a9cf-2f46d6f683b9",
   "metadata": {},
   "source": [
    "---\n",
    "&#9989; **Do This**: Give a short discussion of the comparison between the results from the different classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70602a9",
   "metadata": {},
   "source": [
    "-----\n",
    "### Congratulations, we're done!\n",
    "\n",
    "Now, you just need to submit this assignment by uploading it to the course <a href=\"https://d2l.msu.edu/\">Desire2Learn</a> web page for today's submission folder (Don't forget to add your names in the first cell).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c5e3b-c1eb-4be2-8da6-3027105e540c",
   "metadata": {},
   "source": [
    "&#169; Copyright 2025, The Department of Computational Mathematics, Science and Engineering; Michigan State University"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
